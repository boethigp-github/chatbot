import json
from server.app.clients.base_client import BaseClient
from openai import OpenAI
from cachetools import TTLCache

class OpenAIClient(BaseClient):
    def __init__(self, api_key):
        if not api_key:
            raise ValueError("OpenAI API key is not set")
        self.client = OpenAI(api_key=api_key)


        from flask import current_app
        self.cache = current_app.extensions['cache']


        self.logger = current_app.logger

    def generate(self, prompt: str, **kwargs):
        """
        Generate a completion for a given prompt using the OpenAI API.

        Args:
            prompt (str): The prompt to send to the OpenAI model.
            **kwargs: Additional parameters like model, max_tokens, etc.

        Returns:
            str: The content generated by the model.
        """
        response = self.client.chat.completions.create(
            model=kwargs.get('model', 'gpt-3.5-turbo'),
            messages=[{"role": "user", "content": prompt}],
            max_tokens=kwargs.get('max_tokens', 1000),
            temperature=kwargs.get('temperature', 0.7),
        )
        return response.choices[0].message['content']




    def get_available_models(self):
        """
        Get a list of available models from OpenAI, with caching using cachetools.

        Returns:
            list: A list of model IDs available in the OpenAI account.
        """

        cached_models = self.cache.get('models')
        if cached_models:
            self.logger.debug(f"Cache Hit on get_available_models()")
            return self.cache.get('models')

        self.logger.debug(f"Cache misses.")
        try:
            # List all models available in the account
            response = self.client.models.list()
            models = [model.id for model in response]

            # Cache the result
            self.cache.set('models', models, expire=3600)
            self.logger.debug(f"Cache  {len(models)} Models")


            return models
        except Exception as e:
            # Log the detailed error before raising an exception
            self.logger.error(f"Failed to fetch models from OpenAI: {str(e)}", exc_info=True)
            raise ValueError(f"Error fetching models from OpenAI: {str(e)}")